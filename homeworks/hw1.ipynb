{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rUp2xWkdGFu"
   },
   "source": [
    "# Homework 1: Autoregressive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Theory (5pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLGp4c5UPByO"
   },
   "source": [
    "### Problem 1: Sampling from KDE (2pt)\n",
    "\n",
    "Let $\\hat{p}_h(x) = \\frac{1}{n h^d} \\sum\\limits_{i = 1}^{n} K\\left(\\frac{x - X_i}{h}\\right)$ is the Kernel Density Estimator (see seminar 1) of a density $p_{\\pi}$, where $X_1, \\dots, X_n \\sim p_{\\pi}$, $X_i \\in \\mathbb{R}^d$.\n",
    "\n",
    "Consider the following sampling scheme:\n",
    ">\n",
    ">1. Choose random number $k$ uniformly from the collection of numbers $\\{1, 2, \\dots, n\\}$.\n",
    ">\n",
    ">2. Sample the random variable $\\tilde{X}$ from the kernel $\\frac{1}{h^d} K\\left(\\frac{x - X_k}{h}\\right)$.\n",
    ">\n",
    "\n",
    "Prove, that $\\tilde{X}$ is distributed according to $\\hat{p}_h(x)$, i.e. the scheme above is the correct sampling scheme for $\\hat{p}_h(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0HFuytJPQ7o"
   },
   "source": [
    "```\n",
    "your solution for problem 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tk8-eCJuaTrU",
    "tags": []
   },
   "source": [
    "### Problem 2: MADE theory (2pt)\n",
    "\n",
    "Consider the [MADE](https://arxiv.org/abs/1502.03509) model with a single hidden layer (we have discussed it at seminar 2). The input object is $\\mathbf{x} \\in \\mathbb{R}^m$. We denote by $\\mathbf{W} \\in \\mathbb{R}^{h \\times m}$ the matrix of weights between the input and the hidden layer, and by $\\mathbf{V} \\in \\mathbb{R}^{m \\times h}$ the matrix of weights between the hidden and the output layer ($h$ is the number of neurons in the hidden layer). Let us generate the correct autoregressive masks $\\mathbf{M}_{\\mathbf{W}} \\in \\mathbb{R}^{h \\times m}$ and $\\mathbf{M}_{\\mathbf{V}} \\in \\mathbb{R}^{m \\times h}$ (the generation algorithm is given in Lecture 1) for the direct order of variables\n",
    "$$\n",
    "    p(\\mathbf{x}) = p(x_1) \\cdot p(x_2 | x_1) \\cdot \\dots \\cdot p(x_m | x_{m-1}, \\dots, x_1).\n",
    "$$ \n",
    "(The order of neurons is given by indices at the probabilities in the formula. In this case, it is a direct order.)\n",
    "\n",
    "Each mask is a binary matrix of 0 and 1. Let's introduce the matrix $\\mathbf{M} = \\mathbf{M}_{\\mathbf{V}} \\mathbf{M}_{\\mathbf{W}}$. Prove that:\n",
    "* $\\mathbf{M}$ is strictly lower triangular (has zeros on the diagonal and above the diagonal);\n",
    "* $\\mathbf{M}_{ij}$  is equal to the number of paths in the network graph between the output neuron $\\hat{x}_i$ and the input neuron $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erVRXwzqPHwV"
   },
   "source": [
    "```\n",
    "your solution for problem 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivV4DY1SPEIL"
   },
   "source": [
    "### Problem 3: $\\alpha$-divergence (1pt)\n",
    "\n",
    "In the course, we will meet different divergences (not only $KL$). So let's get acquainted with the class of $\\alpha$-divergences:\n",
    "$$\n",
    "    D_{\\alpha}(p || q) = \\frac{4}{1 - \\alpha^2} \\left( 1 - \\int p(x)^{\\frac{1 + \\alpha}{2}}q(x)^{\\frac{1 - \\alpha}{2}}dx\\right).\n",
    "$$\n",
    "For each $\\alpha \\in [-\\infty; +\\infty]$ the function $D_{\\alpha} (p || q)$ is a measure of the similarity between two distributions. $D_{\\alpha} (p || q)$ has different properties for different $\\alpha$.\n",
    "\n",
    "Prove that for $\\alpha \\rightarrow 1$ the divergence $D_{\\alpha}(p || q) \\rightarrow KL(p || q)$, and for $\\alpha \\rightarrow -1$ the divergence $D_{\\alpha}(p || q) \\rightarrow KL(q || p)$. \n",
    "\n",
    "**Hint:** use the fact that $t^\\varepsilon = \\exp(\\varepsilon \\cdot \\ln t) = 1 + \\varepsilon \\cdot \\ln t + O(\\varepsilon^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution for problem 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4*: Histogram for continuous random vectors in $\\mathbb{R}^d$ (extra 2pt)\n",
    "\n",
    "Let $\\xi \\in \\mathbb{R}^d$ is an absolutely continuous random vector in with probability density function $p_{\\xi}(x)$ , such that $\\,\\text{supp}(p_{\\xi}) \\subseteq [0, 1]^{d}$ ($p_{\\xi}(x) = 0 \\,\\, \\forall x \\in \\mathbb{R}^d \\backslash [0, 1]^d$). Additionally assume, that $p_{\\xi}$ is *Lipschitz continuous* with Lipschitz constant $L$, i.e.:\n",
    "$$\n",
    "\\vert p_{\\xi}(x) - p_{\\xi}(y) \\vert \\leq L \\Vert x - y \\Vert_2\\ \\forall x, y \\in \\mathbb{R}^d .\n",
    "$$  \n",
    "\n",
    "Let $X_1, X_2, \\dots, X_n$ be i.i.d sample from $\\xi$. Consider dividing the hypercube $[0, 1]^d$ into subcubes $C_1, C_2, \\dots, C_N$ with the side length equals to $h$ (i.e. we obtain $N = \\left(\\frac{1}{h}\\right)^{d}$ subcubes). The histogram density estimator is as follows: \n",
    "\n",
    "$$\n",
    "\\hat{p}_h(x) = \\sum\\limits_{j = 1}^{N} \\frac{\\hat{\\theta_j}}{h^d} I\\left( x \\in C_j\\right).\n",
    "$$\n",
    "\n",
    "In the equation above $I(\\,\\cdot\\,)$ is the indicator function and $\\hat{\\theta_j} = \\frac{1}{n} \\sum\\limits_{i = 1}^{n} I(X_i \\in C_j)$.\n",
    "\n",
    "Let's estimate the discrepancy between true density $p_{\\xi}(x)$ and histogram density estimator $\\hat{p}_h(x)$. Consider the $MSE(x, h) = \\mathbb{E}(\\hat{p}_h(x)) - p_{\\xi}(x))^2$ (the expectation is taken over sample $X_1, \\dots, X_n$). \n",
    "\n",
    "* (a) Find an upper bound on $MSE(x, h)$ in terms of $L, h, d, n$. (**Hint:** utilize bias - variance decomposition and deal with each term separately) \n",
    "\n",
    "* (b) Find $h = h_n$ which minimizes the upper bound on $MSE(x, h)$. At which rate $MSE(x, h_n)$ converges to zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution for problem 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2LH7vKPPVUt"
   },
   "source": [
    "Now it time to move on to practical part of homework.\n",
    "\n",
    "In our course we have a small util [package](https://github.com/r-isachenko/2022-DGM-Ozon-course/blob/main/homeworks/dgm_utils/utils.py) with some usefull functions for loading and visualizing the images and training plots. In each homework there is a cell with installing this package. Please read carefully what functions we have in this package. It could help you to solve the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wXq7VJ_SRAl",
    "outputId": "4e0ff17d-460a-4cf3-9b61-e68aafeba295"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = \"2022-2023-DGM-AIMasters-course\"\n",
    "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
    "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
    "!cd {REPO_NAME}\n",
    "!pip install ./{REPO_NAME}/homeworks/\n",
    "!rm -Rf {REPO_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-44Dxk6SRAp"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import train_model, plot_training_curves\n",
    "from dgm_utils import show_samples, visualize_images, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zk6rWePvdGFv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m5NVPFaJGHO",
    "outputId": "506a03c5-4bea-49c3-bf41-12f15e190736"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHouHarf_Hs-"
   },
   "source": [
    "## Task 2: PixelCNN on MNIST (5pt)\n",
    "\n",
    "[PixelCNN](https://arxiv.org/abs/1601.06759) model uses masked causal convoultions on images, we have discussed this model on the lecture 2.\n",
    "\n",
    "Here you have to train this model on MNIST images. See paper for details.\n",
    "\n",
    "Download the data from [here](https://drive.google.com/file/d/1eTH_3i6yShm5yQikO0KdDEG3Hue9lNoZ/view?usp=sharing) (you could use the cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ssrb-5jW_Ilh",
    "outputId": "44688928-b681-481c-8d26-f0787811ac5a"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1eTH_3i6yShm5yQikO0KdDEG3Hue9lNoZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "PiOBcSvx_PN8",
    "outputId": "2a8464be-ac67-4fda-cb82-2e8d0a90c385"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = load_pickle('/content/mnist.pkl', flatten=False, binarize=True)\n",
    "# train_data, test_data = load_pickle('./mnist.pkl', flatten=False, binarize=True)\n",
    "visualize_images(train_data, 'MNIST samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elXdTtB7_6Xl"
   },
   "source": [
    "Masked Convolution Layer is the basic building block of PixelCNN model. Now you have to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybALnsgO_PRW"
   },
   "outputs": [],
   "source": [
    "class MaskedConv2d(nn.Conv2d):\n",
    "    def __init__(self, mask_type: str, in_channels: int, out_channels: int, kernel_size: int = 5) -> None:\n",
    "        assert mask_type in ['A', 'B']\n",
    "        super().__init__(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.register_buffer('mask', torch.zeros_like(self.weight))\n",
    "        self.create_mask(mask_type)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def create_mask(self, mask_type: str) -> None:\n",
    "        # ====\n",
    "        # your code\n",
    "        # do not forget about mask_type\n",
    "        \n",
    "        # ====\n",
    "\n",
    "\n",
    "def test_masked_conv2d():\n",
    "    layer = MaskedConv2d('A', 2, 2)\n",
    "    assert np.allclose(layer.mask[:, :, 2, 2].numpy(), np.zeros((2, 2)))\n",
    "\n",
    "    layer = MaskedConv2d('B', 2, 2)\n",
    "    assert np.allclose(layer.mask[:, :, 2, 2].numpy(), np.ones((2, 2)))\n",
    "\n",
    "\n",
    "test_masked_conv2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPw0osOrAJFm"
   },
   "source": [
    "[Layer Normalization](https://arxiv.org/abs/1607.06450) helps to stabilize training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npUNrimpAGUZ"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.LayerNorm):\n",
    "    def __init__(self, n_filters: int) -> None:\n",
    "        super().__init__(n_filters)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = super().forward(x)\n",
    "        return x.permute(0, 3, 1, 2).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11_PstPkAXig"
   },
   "source": [
    "Now we are ready to construct the main PixelCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xC6E-hrHALYf"
   },
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_shape: Tuple, \n",
    "        n_filters: int = 64, \n",
    "        kernel_size: int = 7, \n",
    "        n_layers: int = 5, \n",
    "        use_layer_norm: bool = True\n",
    "    ) -> None:\n",
    "      \n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply the sequence of MaskedConv2d -> LayerNorm (it is optional) -> ReLU\n",
    "        # the last layer should be MaskedConv2d (not ReLU)\n",
    "        # Note 1: the first conv layer should be of type 'A'\n",
    "        # Note 2: final output_dim in MaskedConv2d must be 2\n",
    "        \n",
    "        # ====\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # read the forward method carefully\n",
    "        batch_size = x.shape[0]\n",
    "        out = (x.float() - 0.5) / 0.5\n",
    "        out = self.net(out)\n",
    "        return out.view(batch_size, 2, 1, *self.input_shape)\n",
    "\n",
    "    def loss(self, x: torch.Tensor) -> dict:\n",
    "        # ====\n",
    "        # your code\n",
    "        \n",
    "        # ====\n",
    "        return {'total_loss': total_loss}\n",
    "\n",
    "    def sample(self, n: int) -> np.ndarray:\n",
    "        # read carefully the sampling process\n",
    "        samples = torch.zeros(n, 1, *self.input_shape).cuda()\n",
    "        with torch.no_grad():\n",
    "            for r in range(self.input_shape[0]):\n",
    "                for c in range(self.input_shape[1]):\n",
    "                    logits = self(samples)[:, :, :, r, c]\n",
    "                    probs = F.softmax(logits, dim=1).squeeze(-1)\n",
    "                    samples[:, 0, r, c] = torch.multinomial(probs, num_samples=1).squeeze(-1)\n",
    "        return samples.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "82b5b39ebb5e43b89442a1321d9c91b9",
      "2803c6582d3e48669d0fef4ca426155c",
      "45e97edbab5d4b649d7a7f4025eea7bd",
      "14e4dcfda7c249c6bb685f025b97f0b3",
      "61f2e439e652405ba58efa1650e46c01",
      "810242c057fc47a387b2048696c21c84",
      "b01ce3a9708f4502be28b50d6826ed5b",
      "8045e5b7a9ed48dbb28a4330d05b5cab",
      "45cb705003dc4a43926a5e6ca3c6e72a",
      "b3d031c7d47a43b6976c4b2d039b3758",
      "733676c2dca14979a91ea1711f23edf2"
     ]
    },
    "id": "9FI5foNQBlr5",
    "outputId": "22e12517-835c-4a45-cbd4-32298d690ffa"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "# (h ere you could see the tips for the hyperparameters, they could help you, \n",
    "# but sometimes you could find more appropriate values,\n",
    "# experiment with them.)\n",
    "EPOCHS =              # > 5\n",
    "BATCH_SIZE =          # any adequate value\n",
    "LR =                  # < 1e-2\n",
    "N_LAYERS =            # < 10\n",
    "N_FILTERS =           # < 128\n",
    "USE_LAYER_NORM = True\n",
    "# ====\n",
    "\n",
    "model = PixelCNN(\n",
    "    input_shape=(28, 28), \n",
    "    n_filters=N_FILTERS, \n",
    "    kernel_size=5, \n",
    "    n_layers=N_LAYERS, \n",
    "    use_layer_norm=USE_LAYER_NORM\n",
    ")\n",
    "\n",
    "loss = model.loss(torch.zeros(1, 1, 28, 28))\n",
    "assert isinstance(loss, dict)\n",
    "assert 'total_loss' in loss\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "train_losses, test_losses = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs=EPOCHS, \n",
    "    lr=LR, \n",
    "    use_tqdm=True, \n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "assert test_losses['total_loss'][-1] < 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLR1d8HICihS"
   },
   "source": [
    "Even if the test loss is bigger than the value in assert, try to visualize train/test curves, it could find you to find the bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "RIiyqsSRCZXs",
    "outputId": "33bc1fb8-6a01-43a9-85a6-52f6a6ed5b1f"
   },
   "outputs": [],
   "source": [
    "plot_training_curves(train_losses, test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdMY__h8CwE5"
   },
   "source": [
    "Now we sample the new images from the model. You have to emphasize that the sampling from the autoregressive model is slow, because it is a sequential process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "skwg5JlRCt0s",
    "outputId": "c5cf5537-84ae-4f13-e2b7-a6fda652eeae"
   },
   "outputs": [],
   "source": [
    "samples = model.sample(25)\n",
    "show_samples(samples, title='MNIST samples', nrow=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUv1QflqDAwk"
   },
   "source": [
    "## Task 3: PixelCNN receptive field and autocompletion (3pt)\n",
    "\n",
    "The PixelCNN model is a powerful model. But the model has drawbacks.\n",
    "\n",
    "1. The model is sequential and sampling is really slow (it is a drawback of all AR models).\n",
    "\n",
    "2. Second, the receptive field of the model is not so large. Even if the model is well-trained, the samples do not have long-range history. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LK1ttmcqfvW"
   },
   "source": [
    "### Receptive field\n",
    "\n",
    "To validate the second point and check our implementation of masked convolutions, let try to visualize the receptive field of the model. \n",
    "\n",
    "We should see that with increasing number of convolutional layers, the receptive field grows. The receptive field can be empirically measured by backpropagating an arbitrary loss for the output features of a specific pixel with respect to the input. We implement this idea below, and visualize the receptive field below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1ekd7rGDBTi"
   },
   "outputs": [],
   "source": [
    "def plot_receptive_field(model: object, model_name: str) -> None:\n",
    "    # ====\n",
    "    # your code\n",
    "    # 1) create tensor with zeros and set required_grad to True.\n",
    "    # 2) apply model to the tensor\n",
    "    # 3) apply backward() to the center pixel of model output\n",
    "    # 4) take the gradient with respect to input\n",
    "    # 5) binary receptive field is an indicator map in which we stay 1's if gradient more than 1e-8\n",
    "    # 6) weighted receptive field is the normalized gradient (values lies in [0, 1])x\n",
    "\n",
    "    # ====\n",
    "\n",
    "    # we stack the maps to get RGB image\n",
    "    binary_map = np.stack([binary_map, binary_map, binary_map], axis=-1)\n",
    "    weighted_map = np.stack([weighted_map, weighted_map, weighted_map], axis=-1)\n",
    "\n",
    "    # center point will be red\n",
    "    binary_map[x_center, y_center] = [1, 0, 0]\n",
    "    weighted_map[x_center, y_center] = [1, 0, 0]\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10, 6))\n",
    "    ax[0].imshow(weighted_map, vmin=0.0, vmax=1.0)\n",
    "    ax[1].imshow(binary_map, vmin=0.0, vmax=1.0)\n",
    "\n",
    "    ax[0].set_title(f\"Weighted receptive field for {model_name}\")\n",
    "    ax[1].set_title(f\"Binary receptive field for {model_name}\")\n",
    "    \n",
    "    ax[0].axis('off')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ruOurWdFDIYP",
    "outputId": "bd34d6a2-a10e-423f-ee62-d48070137066"
   },
   "outputs": [],
   "source": [
    "for n_layers in [1, 3, 5, 6]:\n",
    "    model = PixelCNN(\n",
    "        input_shape=(28, 28), \n",
    "        n_filters=32, \n",
    "        kernel_size=5, \n",
    "        n_layers=n_layers, \n",
    "        use_layer_norm=True\n",
    "    )\n",
    "    if USE_CUDA:\n",
    "        model = model.cuda()\n",
    "    plot_receptive_field(model, model_name=f\"PixelCNN {n_layers} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Njl3VAmruh_v"
   },
   "source": [
    "You have to see that PixelCNN has strange blind spot in binary receptive field plot on the right side. This is a known issue of PixelCNN model. Please, try to understand why it happens. \n",
    "\n",
    "One way to solve this problem is a [GatedPixelCNN](https://arxiv.org/pdf/1606.05328.pdf) model (see paper, if you are interested in)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8eXfFdWzoVu"
   },
   "source": [
    "### Image autocompletion\n",
    "\n",
    "The last feature of autoregressive model that we try is auto-completing an image. As autoregressive models predict pixels one by one, we can set the first pixels to predefined values and check how the model completes the image. \n",
    "\n",
    "For implementing this, we just need to skip the iterations in the sampling loop that already have a value unequals to -1. \n",
    "We redefine the sample method in out PixelCNN class to allow it to take init of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2X24nc_eqET-"
   },
   "outputs": [],
   "source": [
    "class PixelCNNAutoComplete(PixelCNN):\n",
    "    def sample(self, n: int, init: Optional[torch.Tensor] = None) -> np.ndarray:\n",
    "        # ====\n",
    "        # your code\n",
    "        # this method almost the same as the method of the base PixelCNN model\n",
    "        # but now if init is given, this tensor will be used as a starting image. \n",
    "        # The pixels to fill should be -1 in the input tensor.\n",
    "        \n",
    "        # ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6x2bX4Z0w5E"
   },
   "source": [
    "You have to repeat the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e6b80473cd0a47ef83c027fdf1fd0ed9",
      "d334c40c69ae4f73960745abaad192c9",
      "60c098f849364b77bf8e104bd52906fc",
      "b54e291700024a68b62dce374e543b3e",
      "b0c398db58764c2489638b982bcd416d",
      "5d6374ca21ba4763aef5aaf8a22c4f0b",
      "c65445ffee78458aad29d53d5407ebea",
      "f4ca279dda3a48209cdde8380470ff11",
      "eaefcb9391b1498699b73a221161b228",
      "ad6d221ada7f4a04b0495210baadfaf5",
      "8bc321283b51452fb1a177f8d712fdbc"
     ]
    },
    "id": "qFdMAilywnI-",
    "outputId": "5f441176-2ca0-4918-e446-558c1ba8993f"
   },
   "outputs": [],
   "source": [
    "model = PixelCNNAutoComplete(\n",
    "    input_shape=(28, 28), \n",
    "    n_filters=N_FILTERS, \n",
    "    kernel_size=5, \n",
    "    n_layers=N_LAYERS, \n",
    "    use_layer_norm=USE_LAYER_NORM\n",
    ")\n",
    "\n",
    "train_losses, test_losses = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    epochs=EPOCHS, \n",
    "    lr=LR, \n",
    "    use_tqdm=True, \n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "assert test_losses['total_loss'][-1] < 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd9rpg2I0paF"
   },
   "source": [
    "We randomly take images from the training set, mask the lower half of the image (set -1's), and let the model autocomplete it. We do this several times for each image to see the diversity of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "id": "yR0zivWlwsYR",
    "outputId": "44eb5479-b269-4ff6-9b69-769afc50b69e"
   },
   "outputs": [],
   "source": [
    "def autocomplete_image(image: np.ndarray, model: object, n_samples: int) -> None:\n",
    "    # Remove lower half of the image\n",
    "    image_init = image.copy()\n",
    "    image_init[:, image.shape[1] // 2:, :] = -1\n",
    "    samples = np.stack([image, np.maximum(image_init, 0)])\n",
    "    show_samples(samples, title=\"Original image and input image to sampling\", nrow=2)\n",
    "    # Generate completions\n",
    "    image_init = torch.tensor(image_init)\n",
    "    image_init = image_init.unsqueeze(dim=0).expand(n_samples, -1, -1, -1).cuda()\n",
    "    img_generated = model.sample(n_samples, image_init)\n",
    "    show_samples(img_generated, title=\"n_samples\", nrow=4)\n",
    "\n",
    "\n",
    "for i in range(1, 4):\n",
    "    autocomplete_image(train_data[i], model, n_samples=4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw1_solutions_updated.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "784c2e2ba9cdfc1ce1e8c565791a35aa78e810f3990b00899de93c9f5ea5b088"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14e4dcfda7c249c6bb685f025b97f0b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45cb705003dc4a43926a5e6ca3c6e72a",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8045e5b7a9ed48dbb28a4330d05b5cab",
      "value": 10
     }
    },
    "2803c6582d3e48669d0fef4ca426155c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45cb705003dc4a43926a5e6ca3c6e72a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45e97edbab5d4b649d7a7f4025eea7bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b01ce3a9708f4502be28b50d6826ed5b",
      "placeholder": "​",
      "style": "IPY_MODEL_810242c057fc47a387b2048696c21c84",
      "value": "100%"
     }
    },
    "5d6374ca21ba4763aef5aaf8a22c4f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60c098f849364b77bf8e104bd52906fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c65445ffee78458aad29d53d5407ebea",
      "placeholder": "​",
      "style": "IPY_MODEL_5d6374ca21ba4763aef5aaf8a22c4f0b",
      "value": "100%"
     }
    },
    "61f2e439e652405ba58efa1650e46c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_733676c2dca14979a91ea1711f23edf2",
      "placeholder": "​",
      "style": "IPY_MODEL_b3d031c7d47a43b6976c4b2d039b3758",
      "value": " 10/10 [07:21&lt;00:00, 44.00s/it]"
     }
    },
    "733676c2dca14979a91ea1711f23edf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8045e5b7a9ed48dbb28a4330d05b5cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "810242c057fc47a387b2048696c21c84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82b5b39ebb5e43b89442a1321d9c91b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45e97edbab5d4b649d7a7f4025eea7bd",
       "IPY_MODEL_14e4dcfda7c249c6bb685f025b97f0b3",
       "IPY_MODEL_61f2e439e652405ba58efa1650e46c01"
      ],
      "layout": "IPY_MODEL_2803c6582d3e48669d0fef4ca426155c"
     }
    },
    "8bc321283b51452fb1a177f8d712fdbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad6d221ada7f4a04b0495210baadfaf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b01ce3a9708f4502be28b50d6826ed5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0c398db58764c2489638b982bcd416d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc321283b51452fb1a177f8d712fdbc",
      "placeholder": "​",
      "style": "IPY_MODEL_ad6d221ada7f4a04b0495210baadfaf5",
      "value": " 10/10 [07:16&lt;00:00, 44.16s/it]"
     }
    },
    "b3d031c7d47a43b6976c4b2d039b3758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b54e291700024a68b62dce374e543b3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaefcb9391b1498699b73a221161b228",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4ca279dda3a48209cdde8380470ff11",
      "value": 10
     }
    },
    "c65445ffee78458aad29d53d5407ebea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d334c40c69ae4f73960745abaad192c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6b80473cd0a47ef83c027fdf1fd0ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_60c098f849364b77bf8e104bd52906fc",
       "IPY_MODEL_b54e291700024a68b62dce374e543b3e",
       "IPY_MODEL_b0c398db58764c2489638b982bcd416d"
      ],
      "layout": "IPY_MODEL_d334c40c69ae4f73960745abaad192c9"
     }
    },
    "eaefcb9391b1498699b73a221161b228": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4ca279dda3a48209cdde8380470ff11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
