{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRCQvjhe9FYV"
   },
   "source": [
    "# Homework5: Wasserstein GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ptW8_Cp-0W6"
   },
   "source": [
    "## Task 1: Theory (4pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PadvU7YS9FgA"
   },
   "source": [
    "### Problem 1: Importance weighted dequantization (1pt)\n",
    "Let's recall the variational lower bound for the discrete data dequantization from Lecture 7:\n",
    "$$\n",
    "    \\log P(\\mathbf{y} | \\boldsymbol{\\theta}) \\geq  \\int q(\\mathbf{u} | \\mathbf{y}) \\log \\frac{p(\\mathbf{y} + \\mathbf{u} | \\boldsymbol{\\theta})}{q(\\mathbf{u} | \\mathbf{y})} d \\mathbf{u} = \\mathcal{L}(q, \\boldsymbol{\\theta}).\n",
    "$$\n",
    "Previously we have discussed (Lecture 4, IWAE) that the variational lower bound can be improved with the help of Importance Sampling technique. Write out the lower bound for dequantization using $\\mathcal{L}_k$ by analogy with the IWAE model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg5oRBoOWloW"
   },
   "source": [
    "### Problem 2: Least Squares GAN (1pt)\n",
    "    \n",
    "The Vanilla GAN often suffers from problems with a vanishing gradient. [Least Squares GAN](https://arxiv.org/abs/1611.04076) tries to solve this problem by replacing the error function with the following:\n",
    "$$\n",
    "   \t\\min_D V(D) = \\min_D \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - b)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - a)^2 \\right]\n",
    "$$\n",
    "$$\n",
    "   \t\\min_G V(G) = \\min_G \\frac{1}{2}\\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} (D(\\mathbf{x}) - c)^2 + \\mathbb{E}_{p(\\mathbf{z})} (D(G(\\mathbf{z})) - c)^2 \\right],\n",
    "$$\n",
    "where $a,b,c \\in \\mathbb{R}$ some fixed constants.\n",
    "\n",
    "1) Write out the formula for the optimal discriminator $D^*$.\n",
    "  \n",
    "2) Write out the expression for the error function of the generator $V(G)$ in the case of an optimal discriminator $D^*$.\n",
    "  \n",
    "3) Prove that for $b - c = 1$, $b - a = 2$, the error function of the generator $V(G)$ in the case of the optimal discriminator $D^*$ takes the form:\n",
    "$$\n",
    "   \tV(G) = \\chi^2_{\\text{Pearson}} \\left(\\frac{\\pi(\\mathbf{x}) + p(\\mathbf{x} | \\boldsymbol{\\theta})}{2} || p(\\mathbf{x} | \\boldsymbol{\\theta})\\right), \n",
    "$$\n",
    "where $\\chi^2_{\\text{Pearson}} (p || q)$ is a squared Pearson divergence:\n",
    "$$\n",
    "   \t\\chi^2_{\\text{Pearson}} (p || q) = \\int \\frac{(p(\\mathbf{x}) - q(\\mathbf{x}))^2}{p(\\mathbf{x})} d \\mathbf{x}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Gradient Penalty theorem (2pt)\n",
    "\n",
    "In this problem your task is to partially validate the **Gradient Penalty** theorem (*similar to* [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf), *proposition 1*) from the Lecture 10. \n",
    "\n",
    "Recall the Waserstein GAN theoretical setup. Let $\\pi$ and $p$ are two probability measures defined on $\\mathbb{R}^m$. The primal and Kantorovich-Rubinstein (dual) formulations of $1$-Wasserstein distance are as follows:\n",
    "\n",
    "$$\n",
    "W(\\pi \\Vert p) = \\inf\\limits_{\\gamma \\in \\Gamma(\\pi, p)} \\int \\Vert \\mathbf{y} - \\mathbf{z} \\Vert \\gamma(\\mathbf{y}, \\mathbf{z}) d\\mathbf{y} d\\mathbf{z}\\quad \\text{(primal problem)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W(\\pi \\Vert p) = \\sup\\limits_{\\Vert f \\Vert_L \\leq 1} \\left[ \\int f(\\mathbf{x}) \\pi(\\mathbf{x}) d\\mathbf{x} - \\int f(\\mathbf{x}) p(\\mathbf{x}) d\\mathbf{x}\\right] \\quad \\text{(dual problem)}\n",
    "$$\n",
    "\n",
    "Let there exist $\\gamma^* \\in \\arg\\inf\\limits_{\\gamma \\in \\Gamma(\\pi, p)} \\int \\Vert \\mathbf{y} - \\mathbf{z} \\Vert \\gamma(\\mathbf{y}, \\mathbf{z}) d\\mathbf{y} d\\mathbf{z}$ and $f^* \\in \\arg\\sup\\limits_{\\Vert f \\Vert_L \\leq 1} \\left[ \\int f(\\mathbf{x}) \\pi(\\mathbf{x}) d\\mathbf{x} - \\int f(\\mathbf{x}) p(\\mathbf{x}) d\\mathbf{x}\\right]$.\n",
    "\n",
    "Let $f^*$ is differentiable, $\\gamma^*(\\{ \\mathbf{y} = \\mathbf{z}\\}) = 0$. Let $t \\in [0, 1]$. Prove, that $\\mathbb{P}_{(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*} \\left[\\Vert \\nabla f^*(\\mathbf{x})\\big{|}_{\\mathbf{x} = t \\mathbf{y} + (1 - t)\\mathbf{z}}\\Vert = 1\n",
    "\\right]= 1$.\n",
    "\n",
    "In this task we suppose, that the norm $\\Vert \\cdot \\Vert$  is the standard euclidean norm. I.e. $\\Vert \\mathbf{y} - \\mathbf{z} \\Vert = \\sqrt{\\langle \\mathbf{y} - \\mathbf{z}, \\mathbf{y} - \\mathbf{z} \\rangle}$. The $\\langle \\cdot , \\cdot \\rangle$ is standard scalar product.\n",
    "\n",
    "**Hint 1**: Use the statement from the Seminar 10: \n",
    "$$\n",
    "\\mathbb{P}_{(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*} \\left[f^*(\\mathbf{y}) - f^*(\\mathbf{z}) = \\Vert \\mathbf{y} - \\mathbf{z} \\Vert\\right] = 1.\n",
    "$$\n",
    "\n",
    "**Hint 2**: Note, that $f^*$ is 1-Lipshitz.\n",
    "\n",
    "1. Let $(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*$. Given $t \\in [0, 1]$ define $\\mathbf{x}_t = t \\mathbf{y} + (1 - t)\\mathbf{z}$. Prove, that \n",
    "$$\n",
    "\\mathbb{P}_{(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*} \\Big{[}\\sup\\limits_{t \\in [0, 1]} \\big{|} f^*(\\mathbf{x}_t) - f^*(\\mathbf{z}) - t \\Vert \\mathbf{y} - \\mathbf{z} \\Vert\\big{|} = 0\\Big{]} = 1.\n",
    "$$\n",
    "\n",
    "2. Let $(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*$. Define the function $\\phi(t) : [0, 1] \\rightarrow \\mathbb{R}$, $\\phi(t) = f^*(x_t)$. By considering $\\nabla_t \\phi(t)$ prove, that:\n",
    "$$\n",
    "\\forall t \\in [0, 1] \\text{ : }\\mathbb{P}_{(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*} \\big{[}\\langle \\nabla f^*(\\mathbf{x})\\big{|}_{\\mathbf{x} = \\mathbf{x}_t}, \\mathbf{y} - \\mathbf{z}\\rangle = \\Vert \\mathbf{y} - \\mathbf{z} \\Vert\\big{]} = 1.\n",
    "$$\n",
    "\n",
    "3. Prove, that $\\forall t \\in [0, 1]$: \n",
    "$$\n",
    "\\mathbb{P}_{(\\mathbf{y}, \\mathbf{z}) \\sim \\gamma^*} \\big{[}\\nabla f^*(\\mathbf{x})\\big{|}_{\\mathbf{x} = \\mathbf{x}_t} = \\frac{\\mathbf{y} - \\mathbf{z}}{\\Vert \\mathbf{y} - \\mathbf{z} \\Vert}\\big{]} = 1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "your solution\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJQYtKgA5ate",
    "outputId": "be174bfa-d880-41c6-d002-dd8f7ef00fda"
   },
   "outputs": [],
   "source": [
    "REPO_NAME = \"2022-2023-DGM-AIMasters-course\"\n",
    "!if [ -d {REPO_NAME} ]; then rm -Rf {REPO_NAME}; fi\n",
    "!git clone https://github.com/r-isachenko/{REPO_NAME}.git\n",
    "!cd {REPO_NAME}\n",
    "!pip install ./{REPO_NAME}/homeworks/\n",
    "!rm -Rf {REPO_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl59dviN5ekr"
   },
   "outputs": [],
   "source": [
    "from dgm_utils import show_samples, visualize_images, load_pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCNBV60b8CHX",
    "outputId": "ee2145cc-f531-442b-a0b6-ed2eaa59a851"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "print('cuda is available:', USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQb5MtUKd_ii",
    "outputId": "afa023d5-44e7-4d49-d5dd-eaf4c496215b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftMgDK_cPFmD"
   },
   "outputs": [],
   "source": [
    "# do not change this function\n",
    "def plot_losses(losses: np.ndarray, title: str):\n",
    "    n_itr = len(losses)\n",
    "    xs = np.arange(n_itr)\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(xs, losses)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Iterations', fontsize=14)\n",
    "    plt.ylabel('Loss', fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8klUHHmAjHsI"
   },
   "source": [
    "## Task 2: Wasserstein GANs for CIFAR 10 (9pt)\n",
    "\n",
    "In this task you will fit different kinds of Wasserstein GANs (different ways to enforce Lipschitzness) that we discussed in the Lectures 9 and 10 to the CIFAR10 dataset\n",
    "* [WGAN](https://arxiv.org/abs/1701.07875) - standard Wasserstein GAN with weight clipping;\n",
    "* [WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf) - Wasserstein GAN with Gradient Penalty;\n",
    "* [SN-GAN](https://arxiv.org/pdf/1802.05957.pdf) - Wasserstein GAN with Spectral Normalization.\n",
    "\n",
    "\n",
    "Download the data from [here](https://drive.google.com/file/d/1FZcV8Mm91fiXm2jFnB0jvK5ROyHdJFvj/view?usp=sharing) (you could use the cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykn5rCwf7sXZ",
    "outputId": "a9ce3426-731b-422c-8c4b-e6b8582a15bf"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1FZcV8Mm91fiXm2jFnB0jvK5ROyHdJFvj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "dAvSLXlKZ5q7",
    "outputId": "bf78e147-3e5d-4dbc-f854-4b95884bc598"
   },
   "outputs": [],
   "source": [
    "# train_data, test_data = load_pickle('/content/cifar10.pkl')\n",
    "train_data, test_data = load_pickle('/content/drive/MyDrive/DGM/homework_supplementary/cifar10.pkl')\n",
    "visualize_images(train_data, 'CIFAR10 samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PnfAHgw32Hr"
   },
   "source": [
    "### Problem 1: WGAN (3pt)\n",
    "\n",
    "[WGAN](https://arxiv.org/abs/1701.07875) model uses weight clipping to enforce Lipschitzness of the critic.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "\\min_{G} W(\\pi || p) \\approx \\min_{G} \\max_{\\boldsymbol{\\phi} \\in \\boldsymbol{\\Phi}} \\left[ \\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x}, \\boldsymbol{\\phi})  - \\mathbb{E}_{p(\\mathbf{z})} f(G(\\mathbf{z}, \\boldsymbol{\\theta}), \\boldsymbol{\\phi} )\\right].\n",
    "$$\n",
    "Here $f(\\mathbf{x}, \\boldsymbol{\\phi})$ is the critic model. The critic weights $\\boldsymbol{\\phi}$ should lie in the compact set $\\boldsymbol{\\Phi} = [-c, c]^d$.\n",
    "\n",
    "In this task we will use fully-connected networks for the generator $G(\\mathbf{z}, \\boldsymbol{\\theta})$ and the critic $f(\\mathbf{x}, \\boldsymbol{\\phi})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nc9WGmMMkxTU"
   },
   "source": [
    "Here we will use convolution-based generator and critic.\n",
    "\n",
    "First of all, let define generator network. It will be the same for all WGAN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7fjcx0vL8R"
   },
   "outputs": [],
   "source": [
    "class ConvGenerator(nn.Module):\n",
    "    def __init__(self, input_size:int = 128, n_channels: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.input_size = input_size\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) define linear layer with output units 4 * 4 * 4 * n_channels, then relu\n",
    "        # 2) define transposed conv with stride 2, kernel size 2 then BN, then relu\n",
    "        # 3) define transposed conv with stride 2, kernel size 2 then BN, then relu\n",
    "\n",
    "        # ====\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # apply all layers\n",
    "\n",
    "        # ====\n",
    "        return output.view(-1, 3, 32, 32)\n",
    "\n",
    "    def sample(self, n_samples: int) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # sample from standard normal distribution and apply the model\n",
    "\n",
    "        # ===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uVbwHvAruFh"
   },
   "source": [
    "Now it is time to define our critic. Here we will use the same class for all WGAN models, but the arguments will depend on the WGAN mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFA0tI7ZrloP"
   },
   "outputs": [],
   "source": [
    "class ConvCritic(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_channels: int, \n",
    "        conv_layer: Optional[object] = None, \n",
    "        linear_layer: Optional[object] = None, \n",
    "        clip_c: Optional[float] = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.conv_layer = conv_layer or nn.Conv2d\n",
    "        self.linear_layer = linear_layer or nn.Linear\n",
    "        self.clip_c = clip_c\n",
    "        \n",
    "        # ====\n",
    "        # your code\n",
    "        # sequence of convolutional layers and LeakyRelU -> reshape -> FC\n",
    "        # !Note:! use self.conv_layer and self.linear_layer \n",
    "        # (it is important for the SN-GAN model)\n",
    "\n",
    "        # ====\n",
    "        \n",
    "    def clip_weights(self) -> None:\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "                # ====\n",
    "                # your code\n",
    "                # clip the weight to the range [-clip_c, clip_c]\n",
    "                \n",
    "                # ====\n",
    "                layer.weight.data = weight\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # ====\n",
    "        # your code\n",
    "        # 1) clip the critic weights (if clip_c is given)\n",
    "        # 2) apply all layers\n",
    "\n",
    "        # ====\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDi02jfKAVN-"
   },
   "outputs": [],
   "source": [
    "def train_wgan(\n",
    "    generator: object, \n",
    "    critic: object, \n",
    "    train_loader: object,\n",
    "    critic_steps: int, \n",
    "    batch_size: int,\n",
    "    n_epochs: int,\n",
    "    lr: float, \n",
    "    use_cuda: bool = False,\n",
    "    gp_weight: Optional[float]=None\n",
    ") -> dict:\n",
    "\n",
    "    if use_cuda:\n",
    "        critic = critic.cuda()\n",
    "        generator = generator.cuda()\n",
    "    critic.train()\n",
    "    generator.train()\n",
    "\n",
    "    gen_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0, 0.9))\n",
    "    critic_optimizer = torch.optim.Adam(critic.parameters(), lr=lr, betas=(0, 0.9))\n",
    "\n",
    "    curr_iter = 0\n",
    "    d_loss, g_loss = torch.zeros(1), torch.zeros(1)\n",
    "    batch_loss_history = {'discriminator_losses': [], 'generator_losses': []}\n",
    "    for epoch_i in tqdm(range(n_epochs)):\n",
    "        for batch_i, x in enumerate(train_loader):\n",
    "            curr_iter += 1\n",
    "            if use_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "            # do a critic update\n",
    "            critic_optimizer.zero_grad()\n",
    "            fake_data = generator.sample(x.shape[0])\n",
    "\n",
    "            # ====\n",
    "            # your code\n",
    "            # D(x_fake) - D(x_real)\n",
    "\n",
    "            # ====\n",
    "\n",
    "            if gp_weight is not None:\n",
    "                gp = gradient_penalty(critic, x, fake_data)\n",
    "                d_loss += gp_weight * gp\n",
    "\n",
    "            d_loss.backward()\n",
    "            critic_optimizer.step()\n",
    "\n",
    "            # generator update\n",
    "            if curr_iter % critic_steps == 0:\n",
    "                gen_optimizer.zero_grad()\n",
    "                fake_data = generator.sample(batch_size)\n",
    "                # ====\n",
    "                # your code\n",
    "                # -D(x_fake)\n",
    "\n",
    "                # ====\n",
    "                g_loss.backward()\n",
    "                gen_optimizer.step()\n",
    "\n",
    "                batch_loss_history['generator_losses'].append(g_loss.data.cpu().numpy())\n",
    "                batch_loss_history['discriminator_losses'].append(d_loss.data.cpu().numpy())\n",
    "\n",
    "    return batch_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731,
     "referenced_widgets": [
      "d79722ca4124443e803dcf00aed2f722",
      "f9bf0177023f44b0b2a05efc3aa11f2b",
      "b99f8101097344c8848b357a034b36fa",
      "a86ba693a971467699526cda213a76d4",
      "41f06567d74f4c9fb4bcbfb1e5633aea",
      "7edacbf745db465198f2b637ffe93b46",
      "f91d18e5fe244bb8bacc878c1b716f51",
      "51c5c637d74143928ea2dc9e3c6189d3",
      "5da562bea5fd49bda6f9d80effa29de9",
      "a9682c1aec70476a839e4c5384dc1f6d",
      "9326b13aa30043959debdcf51aa5baad"
     ]
    },
    "id": "bjOGNNU59Fr_",
    "outputId": "10c9c464-2cbc-4efa-dfb7-e02bd7262bfd"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters (you have to train the model more than 20 epochs to get good results)\n",
    "BATCH_SIZE =    # any adequate value\n",
    "N_CHANNELS =    # > 32\n",
    "N_EPOCHS =      # > 10\n",
    "CRITIC_STEPS =  # > 2\n",
    "CLIP_C =        # < 1\n",
    "LR =            # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS, clip_c=CLIP_C)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Discriminator loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2oddhso98hq"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "EXWKEKxQ9_DH",
    "outputId": "2c453929-9b71-4243-9e16-a3845004ef35"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "show_samples(samples[:100], title='CIFAR-10 WGAN-generated samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZG4ErQLNjZr9"
   },
   "source": [
    "### Problem 2: WGAN-GP for CIFAR 10 (3pt)\n",
    "\n",
    "[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)  model uses gradient penalty to enforce Lipschitzness.\n",
    "\n",
    "The model objective is\n",
    "$$\n",
    "    W(\\pi || p) = \\underbrace{\\mathbb{E}_{\\pi(\\mathbf{x})} f(\\mathbf{x})  - \\mathbb{E}_{p(\\mathbf{x} | \\boldsymbol{\\theta})} f(\\mathbf{x})}_{\\text{original critic loss}} + \\lambda \\underbrace{\\mathbb{E}_{U[0, 1]} \\left[ \\left( \\| \\nabla_{\\hat{\\mathbf{x}}} f(\\hat{\\mathbf{x}}) \\|_2 - 1 \\right) ^ 2\\right]}_{\\text{gradient penalty}},\n",
    "$$\n",
    "where the samples $\\hat{\\mathbf{x}}_t = t \\mathbf{x} + (1 - t) \\mathbf{y}$ with $t \\in [0, 1]$ are uniformly sampled along straight lines between pairs of points: $\\mathbf{x}$ from the data distribution $\\pi(\\mathbf{x})$ and $\\mathbf{y}$ from the generator distribution $p(\\mathbf{x} | \\boldsymbol{\\theta}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aTCJKgoAuUm"
   },
   "source": [
    "Let define our gradient penalty loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RXJ6autArvg"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(critic: object, real_data: torch.Tensor, fake_data: torch.Tensor) -> torch.Tensor:\n",
    "    batch_size = real_data.shape[0]\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # Calculate interpolation x_t = t * x_real + (1 - t) x_fake\n",
    "    # 1) sample t\n",
    "    # 2) create x_t (be careful about shapes)\n",
    "    # 3) apply critic to x_t\n",
    "\n",
    "    # ====\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_output, \n",
    "        inputs=x_t, \n",
    "        grad_outputs=torch.ones(d_output.size()).to(fake_data.device), \n",
    "        create_graph=True, \n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "\n",
    "    gradients = gradients.reshape(batch_size, -1)\n",
    "    # ====\n",
    "    # your code\n",
    "    # compute gradient norm\n",
    "\n",
    "    # ====\n",
    "    return ((gradients_norm - 1) ** 2).mean()\n",
    "\n",
    "\n",
    "def test_gradient_penalty():\n",
    "    x = np.random.normal(size=(10, 4))\n",
    "    x_norm = np.mean(np.sqrt(x ** 2))\n",
    "    x = torch.randn(size=(10, 4))\n",
    "    x.requires_grad = True\n",
    "    assert gradient_penalty(lambda x: x, x, x).numpy() == 1\n",
    "    assert gradient_penalty(lambda x: x * 0, x, x).numpy() == 1\n",
    "\n",
    "\n",
    "test_gradient_penalty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBRZJXGAryNA"
   },
   "source": [
    "That is all :) \n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731,
     "referenced_widgets": [
      "e907f62f231445e7b1af826de93f3407",
      "9dfdd1b09ef24813bd0a82d021ea5ca2",
      "37e7b70ce4e549ceb089b65a8d448168",
      "0e48558869494144aa8e6ba3cc4dea0e",
      "ca1b7f6c6bd343618c4f37baaee71e51",
      "f13f16f08b2c4b709c1f086880067c16",
      "14d4e8920ab44a809843199d88c7c000",
      "2d81365246cf405eaa9d431da6df0781",
      "24e1187e15324f7ab51819c653af4975",
      "286925d0f0304067b6c4d4ba19761469",
      "c11287b4a0df42daa7fe90c862fcfd39"
     ]
    },
    "id": "aY6qzJ5MSuiX",
    "outputId": "542c5eff-9b68-4faf-e12b-b6e25115f876"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters (you have to train the model more than 20 epochs to get good results)\n",
    "BATCH_SIZE =    # any adequate value\n",
    "N_CHANNELS =    # > 32\n",
    "N_EPOCHS =      # > 10\n",
    "CRITIC_STEPS =  # > 2\n",
    "GP_WEIGHT =     # > 5\n",
    "LR =            # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "generator = ConvGenerator(n_channels=N_CHANNELS)\n",
    "critic = ConvCritic(n_channels=N_CHANNELS)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    gp_weight=GP_WEIGHT,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "plot_losses(train_losses['discriminator_losses'], 'Discriminator loss')\n",
    "plot_losses(train_losses['generator_losses'], 'Generator loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unAqs_pEs59l"
   },
   "source": [
    "Let sample from our model and draw the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "8I0pNzHchqRs",
    "outputId": "68d5782b-4ed0-466a-bfab-273d05fd9b7a"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "show_samples(samples[:100], title='CIFAR-10 WGAN-GP-generated samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-YPxpeDDCU9"
   },
   "source": [
    "### Problem 3: SN-GAN on CIFAR10 (3pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvbrtdFgBTfE"
   },
   "source": [
    "[Spectral Normalization GAN](https://arxiv.org/pdf/1802.05957.pdf) replaces the weights in the critic $f(\\mathbf{x}, \\boldsymbol{\\phi})$ by \n",
    "$$\n",
    "    \\mathbf{W}^{SN} = \\frac{\\mathbf{W}}{\\|\\mathbf{W}\\|_2}.\n",
    "$$\n",
    "\n",
    "This ensures that $\\| f\\|_L \\leq 1.$.\n",
    "\n",
    "Power iteration method allows to efficiently compute $\\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})}$.\n",
    "    \n",
    "The pseudocode of the method is:\n",
    "* $\\mathbf{u}_0$ -- random vector.\n",
    "* for $k = 0, \\dots, n - 1$: \n",
    "$$\n",
    "    \\mathbf{v}_{k+1} = \\frac{\\mathbf{W}^T \\mathbf{u}_{k}}{\\| \\mathbf{W}^T \\mathbf{u}_{k} \\|}, \\quad \\mathbf{u}_{k+1} = \\frac{\\mathbf{W} \\mathbf{v}_{k+1}}{\\| \\mathbf{W} \\mathbf{v}_{k+1} \\|}.\n",
    "$$\n",
    "* approximate the spectral norm\n",
    "$$\n",
    "    \\| \\mathbf{W} \\|_2 = \\sqrt{\\lambda_{\\text{max}}(\\mathbf{W}^T \\mathbf{W})} \\approx \\mathbf{u}_{n}^T \\mathbf{W} \\mathbf{v}_{n}.\n",
    "$$\n",
    "\n",
    "First step is to implement this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-Q1099aBUhF"
   },
   "outputs": [],
   "source": [
    "def power_iteration_method(\n",
    "    W: torch.Tensor, \n",
    "    n_iters: int, \n",
    "    u_init: Optional[nn.Parameter]=None, \n",
    "    v_init: Optional[nn.Parameter]=None\n",
    ") -> tuple:\n",
    "    if u_init is None:\n",
    "        u_init = nn.Parameter(torch.randn(W.shape[0]), requires_grad=False)\n",
    "    if v_init is None:\n",
    "        v_init = nn.Parameter(torch.randn(W.shape[1]), requires_grad=False)\n",
    "\n",
    "    # ====\n",
    "    # your code\n",
    "    # 1) implement for loop and update v_init/u_init\n",
    "    # 2) calculate spectral norm\n",
    "    # 3) return spectral norm (sigma) and the last values for v_init, u_init\n",
    "\n",
    "    # ====\n",
    "    return sigma, u_init, v_init\n",
    "\n",
    "\n",
    "def test_power_iteration_method():\n",
    "    W = np.array([\n",
    "        [1, 2, 3],\n",
    "        [2, 3, 4],\n",
    "        [3, 4, 5]\n",
    "    ], dtype=np.float32)\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "    W_tensor = torch.tensor(W)\n",
    "    sigma, u, v = power_iteration_method(W_tensor, n_iters=10)\n",
    "    np.allclose(S[0], sigma)\n",
    "    np.allclose(u, U[:, 0])\n",
    "    np.allclose(v, V[0, :])\n",
    "\n",
    "\n",
    "test_power_iteration_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skqXws_UBYtn"
   },
   "source": [
    "Now we need to define layers with Spectral Normalization (we will use `SpectralNormConv2D` and `SpectralNormLinear` layers instead of standard `nn.Conv2D` and `nn.Linear` in our critic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3davuPNBZFp"
   },
   "outputs": [],
   "source": [
    "class SpectralNormConv2D(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.power_iterations = kwargs.pop(\"power_iterations\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.u = nn.Parameter(torch.randn(self.weight.shape[0]), requires_grad=False)\n",
    "        self.v = nn.Parameter(torch.randn(self.weight.shape[1]), requires_grad=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        W = self.weight.view(self.weight.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            # ====\n",
    "            # your code\n",
    "            # apply power iteration method\n",
    "\n",
    "            # ====\n",
    "        self.u.data = u.data\n",
    "        self.v.data = v.data\n",
    "        self.weight.data = self.weight.data / sigma\n",
    "        \n",
    "        return super().forward(input)\n",
    "\n",
    "\n",
    "class SpectralNormLinear(nn.Linear):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.power_iterations = kwargs.pop(\"power_iterations\")\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.u = nn.Parameter(torch.randn(self.weight.shape[0]), requires_grad=False)\n",
    "        self.v = nn.Parameter(torch.randn(self.weight.shape[1]), requires_grad=False)\n",
    "        \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        W = self.weight.view(self.weight.shape[0], -1)\n",
    "        with torch.no_grad():\n",
    "            # ====\n",
    "            # your code\n",
    "            # apply power iteration method\n",
    "            \n",
    "            # ====\n",
    "        self.u.data = u.data\n",
    "        self.v.data = v.data\n",
    "        self.weight.data = self.weight.data / sigma\n",
    "        \n",
    "        return super().forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmolmRfl-Ysb"
   },
   "source": [
    "That is all :) \n",
    "\n",
    "We will use the same `ConvGenerator`, `ConvCritic` and `train_wgan()` as for WGAN model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750,
     "referenced_widgets": [
      "7695cf0f33bf494bb0c0555bbea71e62",
      "908e3b2c97ab42618aa38d347a9c01d9",
      "d6b46c7eb6784d5fab531841fac6bba2",
      "5d151d2cd7374dff9abdae2ae9a79b4c",
      "69cb32a589f1405eb182d8cb6248187d",
      "ed47ad4dfcd04b618980703c94264665",
      "8ddbf78a4a5741d1a93d2a5df8e3bb65",
      "7f635bf247cd4e4fb60661ab59f5b8ca",
      "c8f9dfedf1ea4cf5b716404376097447",
      "169c18247df14210968b794806a574cb",
      "dc5b248695bf41c39957007a70be208c"
     ]
    },
    "id": "LOTPsSRkBnj4",
    "outputId": "34acb795-bd8a-4ba9-ba95-861dd0de0f40"
   },
   "outputs": [],
   "source": [
    "# ====\n",
    "# your code\n",
    "# choose these parameters\n",
    "BATCH_SIZE =        # any adequate value\n",
    "DIM =               # > 32\n",
    "N_EPOCHS =          # > 20 \n",
    "CRITIC_STEPS =      # 1 < x < 10\n",
    "POWER_ITERATIONS =  # 1 < x < 5\n",
    "LR =                # < 1e-3\n",
    "# ====\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Total number of epochs:', N_EPOCHS)\n",
    "\n",
    "generator = ConvGenerator(n_channels=DIM)\n",
    "conv_layer = partial(SpectralNormConv2D, power_iterations=POWER_ITERATIONS)\n",
    "linear_layer = partial(SpectralNormLinear, power_iterations=POWER_ITERATIONS)\n",
    "critic = ConvCritic(n_channels=DIM, conv_layer=conv_layer, linear_layer=linear_layer)\n",
    "\n",
    "train_losses = train_wgan(\n",
    "    generator, \n",
    "    critic, \n",
    "    train_loader,\n",
    "    critic_steps=CRITIC_STEPS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    n_epochs=N_EPOCHS,\n",
    "    lr=LR,\n",
    "    use_cuda=USE_CUDA\n",
    ")\n",
    "\n",
    "g_losses = train_losses['generator_losses']\n",
    "d_losses = train_losses['discriminator_losses']\n",
    "\n",
    "plot_losses(g_losses, 'Generator loss')\n",
    "plot_losses(d_losses, 'Discriminator loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "JbOGh6mYBpxu",
    "outputId": "aec6be24-b02d-41c2-91a1-b26938dc3f29"
   },
   "outputs": [],
   "source": [
    "generator.eval()\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    samples = generator.sample(1000)\n",
    "    samples = samples.cpu().detach().numpy()\n",
    "    \n",
    "\n",
    "show_samples(samples[:100], title='CIFAR-10 generated samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqk96UWO-7eZ"
   },
   "source": [
    "You are really welcome to experiment with combination of three approaches to get best samples :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e48558869494144aa8e6ba3cc4dea0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_286925d0f0304067b6c4d4ba19761469",
      "placeholder": "​",
      "style": "IPY_MODEL_c11287b4a0df42daa7fe90c862fcfd39",
      "value": " 20/20 [03:12&lt;00:00,  9.60s/it]"
     }
    },
    "14d4e8920ab44a809843199d88c7c000": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "169c18247df14210968b794806a574cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24e1187e15324f7ab51819c653af4975": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "286925d0f0304067b6c4d4ba19761469": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d81365246cf405eaa9d431da6df0781": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37e7b70ce4e549ceb089b65a8d448168": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d81365246cf405eaa9d431da6df0781",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24e1187e15324f7ab51819c653af4975",
      "value": 20
     }
    },
    "41f06567d74f4c9fb4bcbfb1e5633aea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51c5c637d74143928ea2dc9e3c6189d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d151d2cd7374dff9abdae2ae9a79b4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_169c18247df14210968b794806a574cb",
      "placeholder": "​",
      "style": "IPY_MODEL_dc5b248695bf41c39957007a70be208c",
      "value": " 30/30 [02:40&lt;00:00,  5.30s/it]"
     }
    },
    "5da562bea5fd49bda6f9d80effa29de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69cb32a589f1405eb182d8cb6248187d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7695cf0f33bf494bb0c0555bbea71e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_908e3b2c97ab42618aa38d347a9c01d9",
       "IPY_MODEL_d6b46c7eb6784d5fab531841fac6bba2",
       "IPY_MODEL_5d151d2cd7374dff9abdae2ae9a79b4c"
      ],
      "layout": "IPY_MODEL_69cb32a589f1405eb182d8cb6248187d"
     }
    },
    "7edacbf745db465198f2b637ffe93b46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f635bf247cd4e4fb60661ab59f5b8ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ddbf78a4a5741d1a93d2a5df8e3bb65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "908e3b2c97ab42618aa38d347a9c01d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed47ad4dfcd04b618980703c94264665",
      "placeholder": "​",
      "style": "IPY_MODEL_8ddbf78a4a5741d1a93d2a5df8e3bb65",
      "value": "100%"
     }
    },
    "9326b13aa30043959debdcf51aa5baad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9dfdd1b09ef24813bd0a82d021ea5ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f13f16f08b2c4b709c1f086880067c16",
      "placeholder": "​",
      "style": "IPY_MODEL_14d4e8920ab44a809843199d88c7c000",
      "value": "100%"
     }
    },
    "a86ba693a971467699526cda213a76d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9682c1aec70476a839e4c5384dc1f6d",
      "placeholder": "​",
      "style": "IPY_MODEL_9326b13aa30043959debdcf51aa5baad",
      "value": " 20/20 [01:42&lt;00:00,  5.10s/it]"
     }
    },
    "a9682c1aec70476a839e4c5384dc1f6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b99f8101097344c8848b357a034b36fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c5c637d74143928ea2dc9e3c6189d3",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5da562bea5fd49bda6f9d80effa29de9",
      "value": 20
     }
    },
    "c11287b4a0df42daa7fe90c862fcfd39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8f9dfedf1ea4cf5b716404376097447": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ca1b7f6c6bd343618c4f37baaee71e51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6b46c7eb6784d5fab531841fac6bba2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f635bf247cd4e4fb60661ab59f5b8ca",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c8f9dfedf1ea4cf5b716404376097447",
      "value": 30
     }
    },
    "d79722ca4124443e803dcf00aed2f722": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9bf0177023f44b0b2a05efc3aa11f2b",
       "IPY_MODEL_b99f8101097344c8848b357a034b36fa",
       "IPY_MODEL_a86ba693a971467699526cda213a76d4"
      ],
      "layout": "IPY_MODEL_41f06567d74f4c9fb4bcbfb1e5633aea"
     }
    },
    "dc5b248695bf41c39957007a70be208c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e907f62f231445e7b1af826de93f3407": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9dfdd1b09ef24813bd0a82d021ea5ca2",
       "IPY_MODEL_37e7b70ce4e549ceb089b65a8d448168",
       "IPY_MODEL_0e48558869494144aa8e6ba3cc4dea0e"
      ],
      "layout": "IPY_MODEL_ca1b7f6c6bd343618c4f37baaee71e51"
     }
    },
    "ed47ad4dfcd04b618980703c94264665": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f13f16f08b2c4b709c1f086880067c16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f91d18e5fe244bb8bacc878c1b716f51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9bf0177023f44b0b2a05efc3aa11f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7edacbf745db465198f2b637ffe93b46",
      "placeholder": "​",
      "style": "IPY_MODEL_f91d18e5fe244bb8bacc878c1b716f51",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
